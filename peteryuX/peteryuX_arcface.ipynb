{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArcFace\n",
    "reference : https://github.com/peteryuX/arcface-tf2#Installation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setting\n",
    "**repository clone**\n",
    "> git clone https://github.com/peteryuX/arcface-tf2.GeneratorExit\n",
    "> cd arcface-tf2\n",
    "\n",
    "**conda** \n",
    "> conda env create -f environment.yml\n",
    "> conda activate arcface-tf2  \n",
    "\n",
    "**pip**   \n",
    "> pip install -r requirement.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparing\n",
    "- dataset : htttps://www.github.com/ZhaoJ9014/face/evoLVe  \n",
    "memo : 교육 및 테스트 데이터 세트는 모두 \"Align_112x112\"ver\n",
    "### Training Dataset\n",
    "Download MS-Celeb-1M : https://drive.google.com/file/d/1X202mvYe5tiXFhOx82z4rPiPogXD435i/view?usp=sharing  \n",
    "- Datasets을 다운로드한 후 그것을 추출하고 tfrecord로 변환한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진 이미지 : convert realyy slow, but loading faster when traning.\n",
    "!python data/convert_train_binary_tfrecord.py --datset_pat=\"/path/to/msim_align_112/imgs  --output_path=\"./data/ms1m_bin.tfrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 온라인 이미지 로딩 : convert really fast, but loading slower when training\n",
    "!ptrhon data/conver_train_tfrecord.py --dataset_path=\"/path/to/ms1m_align_112/imgs\" --output_path=\"./data/ms1m.tfrecord\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset\n",
    "Download LFW : https://drive.google.com/file/d/1WO5Meh_yAau00Gm2Rz2Pc0SRldLQYigT/view?usp=sharing  \n",
    "- memo : these data are already binary file, so it's not necessray to do any preprocessing "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 로더가 작동하는지 확인할 때 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./dataset_checker.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traing and Test\n",
    "교육 및 테스트를 위해 **./configs/*.yaml** 에서 자신의 데이터 세트 경로 또는 기타 모델 설정을 수정할 수 있다. \n",
    "- sub_name : 검사점 및 로그 폴더에서 사용되는 출력 디렉터리의 이름이다.  \n",
    "- head_type : 훈련에서 분류를 위해 ArcFace 헤드 또는 일반 완전 연결 레이어 헤드를 선택하는 데 사용된다.   \n",
    "***참조*** : ./modules/models.py\n",
    "- is_ccrop : 훈련 및 테스트 데이터 모두에서 중앙 자르기를 수행하는지 여부 의미\n",
    "- binary_img : Data-Preparing에서 생성한 데이터 유형에 따라야 하는 학습 데이터 유형을 선태하는데 사용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with tf.GradientTape(), great for debugging.\n",
    "!python train.py --mode=\"eager_tf\" --cfg_path=\"./configs/arc_res50.yaml\"\n",
    "\n",
    "# training with model.fit()\n",
    "!python train.py --mode=\"fit\" --cfg_path=\"./configs/arc_res50.yaml\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --cfg_path=\"./configs/arc_res50.yaml\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력 이미지 인코딩\n",
    "모델별로 이미지를 잠재 벡터로 인코딩 할 수 있다. 예를 들어 ./data/BruceLee.jpg에서 이미지를 인코딩 하고,  \n",
    "./output_embeds.npy에 저장 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --cfg_path=:./configs/arc_res50.yaml\" --img_path=\"./data/BruceLee.jpg\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcface-tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4578fa1366871325209ea4c1699c8a97cc771675995af43cf6360d039f36fb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
